{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "Adapted from [Training with PyTorch](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import transforms as tv_transfroms\n",
    "\n",
    "from models.fcn_factory import FcnFactory\n",
    "from preprocess.datasets import make_hou_dataset\n",
    "from preprocess import transforms as custom_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA version: 11.8\n",
      "CUDA available: True\n",
      "Device ID: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'CUDA version: {torch.version.cuda}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "print(f'Device ID: {torch.cuda.current_device()}')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "RANDOM_STATE = 42\n",
    "rng = torch.Generator().manual_seed(RANDOM_STATE)\n",
    "N_BATCHES_FOR_RECORD = 10\n",
    "# Runs\n",
    "EPOCHS = 10\n",
    "# Data loading\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = FcnFactory(n_classes=2)\n",
    "model = factory.make_fcn('resnet50').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model input/output transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_shape(model, in_transform) -> list:\n",
    "    dummy_input = torch.randn((1, 3, 256, 256)).to(device)\n",
    "    return list(model(in_transform(dummy_input))['out'].shape[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_transforms = factory.input_transforms\n",
    "output_h_w = get_output_shape(model, input_transforms)\n",
    "mask_transforms = tv_transfroms.Compose(\n",
    "    [\n",
    "        tv_transfroms.Resize(output_h_w),\n",
    "        tv_transfroms.Lambda(custom_transforms.one_hot),\n",
    "    ]\n",
    ")\n",
    "# some checks\n",
    "assert output_h_w == [520, 520] # this is the size for this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hou\n",
    "# Excluding this directory because the masks apper to be wrong\n",
    "EXCLUDE_DIRS = (Path('data/Hou/PV03_Ground_WaterSurface'),)\n",
    "hou_ds = make_hou_dataset(\n",
    "    EXCLUDE_DIRS,\n",
    "    img_transforms=input_transforms,\n",
    "    mask_transforms=mask_transforms,\n",
    ")\n",
    "\n",
    "# Split datasets\n",
    "train_ds, val_ds, test_ds = random_split(hou_ds, [0.6, 0.2, 0.2], generator=rng)\n",
    "\n",
    "# Loading the data\n",
    "train_loader = DataLoader(train_ds, BATCH_SIZE, shuffle=True, generator=rng)\n",
    "val_loader = DataLoader(val_ds, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss_mean = 0.\n",
    "\n",
    "    # Here, we use enumerate(train_loader) instead of\n",
    "    # iter(train_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        inputs, labels = batch\n",
    "        # move data to GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)['out']\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimiser.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % N_BATCHES_FOR_RECORD == N_BATCHES_FOR_RECORD - 1:\n",
    "            last_loss_mean = running_loss / N_BATCHES_FOR_RECORD # loss per batch\n",
    "            print(f'\\tBatches {i-N_BATCHES_FOR_RECORD+2}-{i+1} mean loss: {last_loss_mean}')\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss_mean, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "\tBatches 1-10 mean loss: 0.4820940881967545\n",
      "\tBatches 11-20 mean loss: 0.3197287768125534\n",
      "\tBatches 21-30 mean loss: 0.2774208799004555\n",
      "\tBatches 31-40 mean loss: 0.22921065837144852\n",
      "\tBatches 41-50 mean loss: 0.20369807332754136\n",
      "LOSS train 0.20369807332754136 valid 0.18774618208408356\n",
      "EPOCH 2:\n",
      "\tBatches 1-10 mean loss: 0.19680357128381729\n",
      "\tBatches 11-20 mean loss: 0.1758433535695076\n",
      "\tBatches 21-30 mean loss: 0.17454831302165985\n",
      "\tBatches 31-40 mean loss: 0.1855638101696968\n",
      "\tBatches 41-50 mean loss: 0.1983269691467285\n",
      "LOSS train 0.1983269691467285 valid 0.19255037605762482\n",
      "EPOCH 3:\n",
      "\tBatches 1-10 mean loss: 0.1682751163840294\n",
      "\tBatches 11-20 mean loss: 0.16786079108715057\n",
      "\tBatches 21-30 mean loss: 0.17362866178154945\n",
      "\tBatches 31-40 mean loss: 0.16725173443555832\n",
      "\tBatches 41-50 mean loss: 0.17151171565055848\n",
      "LOSS train 0.17151171565055848 valid 0.1489190310239792\n",
      "EPOCH 4:\n",
      "\tBatches 1-10 mean loss: 0.14808582365512848\n",
      "\tBatches 11-20 mean loss: 0.18569454848766326\n",
      "\tBatches 21-30 mean loss: 0.16824840754270554\n",
      "\tBatches 31-40 mean loss: 0.14812038466334343\n",
      "\tBatches 41-50 mean loss: 0.13524914309382438\n",
      "LOSS train 0.13524914309382438 valid 0.14665013551712036\n",
      "EPOCH 5:\n",
      "\tBatches 1-10 mean loss: 0.1643732227385044\n",
      "\tBatches 11-20 mean loss: 0.1486518017947674\n",
      "\tBatches 21-30 mean loss: 0.15940216556191444\n",
      "\tBatches 31-40 mean loss: 0.14714056625962257\n",
      "\tBatches 41-50 mean loss: 0.1468069389462471\n",
      "LOSS train 0.1468069389462471 valid 0.1387874335050583\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/ResNet-50{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            # move to GPU\n",
    "            vinputs = vinputs.to(device)\n",
    "            vlabels = vlabels.to(device)\n",
    "            voutputs = model(vinputs)['out']\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'saved_models/test_data/test_ds_{timestamp}', 'wb') as f:\n",
    "    pickle.dump(test_ds, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
